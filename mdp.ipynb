{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/vbipin/aip/blob/master/mdp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pr2dA9HmkePh"
   },
   "outputs": [],
   "source": [
    "#we plan to implement some of the algorithms related to MDPs and RL\n",
    "#MDP study\n",
    "#%matplotlib inline\n",
    "#import matplotlib\n",
    "#import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "#I am trying to avoid the numpy dependencies\n",
    "\n",
    "import random\n",
    "#\n",
    "#We plan to implement the gridworld class \n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NU8O0Do5k-8S"
   },
   "outputs": [],
   "source": [
    "#Let us have a gridworld\n",
    "#ref: Chapter 17, Artificial Intelligence a Modern Approach\n",
    "#ref: CS188 https://inst.eecs.berkeley.edu/~cs188/fa19/\n",
    "#ref: https://inst.eecs.berkeley.edu/~cs188/fa19/assets/slides/lec8.pdf\n",
    "#ref: https://courses.cs.washington.edu/courses/cse473/13au/slides/17-mdp-rl.pdf\n",
    "\n",
    "#This class will create a 2D grid of row x colums \n",
    "#Some of the cells can be disabled by putting it into walls\n",
    "#cells are addressed just like 2d arrays (r,c)\n",
    "#There are possibly many terminal states\n",
    "#terminal states have only one action available: Exit \n",
    "#Transistion is as per the book 80% action and 20%sideways ( a variable noise is used to control this distribution)\n",
    "#There is a special end state, (-1,-1), from which NO action is available. This state is used as a final state.\n",
    "\n",
    "#Actions #just some alias\n",
    "Up    = 0\n",
    "Down  = 1\n",
    "Right = 2\n",
    "Left  = 3\n",
    "Exit  = 4\n",
    "\n",
    "class GridWorld :\n",
    "    #Default is as given in the AIMA book\n",
    "    def __init__(self, \n",
    "                 rows    =3, \n",
    "                 columns =4, \n",
    "                 walls   =[(1,1)], terminals= {(0,3):+1.0, (1,3):-1.0}, \n",
    "                 gamma   =1.0, \n",
    "                 living_reward=0,\n",
    "                 noise   =0.2\n",
    "                ) :\n",
    "        \"\"\"We dont expect these parameters to change during the agent run\"\"\"\n",
    "        self.rows      = rows\n",
    "        self.columns   = columns\n",
    "        self.N         = rows * columns #total cells\n",
    "        self.walls     = walls\n",
    "        self.terminals = terminals #dictionary of terminal celss and their rewards.\n",
    "        self.gamma     = gamma\n",
    "        self.living_reward = living_reward\n",
    "        self.all_actions   = [ Up, Down, Right, Left, Exit ]\n",
    "        self.end_state     = (-1, -1) #a dummy state to reach after taking Exit\n",
    "        self.all_states    = [(r,c) for r in range(rows) for c in range(columns) if (r,c) not in walls ] + [self.end_state]\n",
    "        self.noise         = noise\n",
    "        \n",
    "        \n",
    "        #transitions from each state and the probabilities\n",
    "        self.noise                = noise\n",
    "        self.action_transitions   = { \n",
    "            Up:   ([Up,    Left, Right], [1-noise, noise/2, noise/2 ]),\n",
    "            Down: ([Down,  Left, Right], [1-noise, noise/2, noise/2 ]),\n",
    "            Left: ([Left,  Up,   Down ], [1-noise, noise/2, noise/2 ]),\n",
    "            Right:([Right, Up,   Down ], [1-noise, noise/2, noise/2 ]),\n",
    "            Exit :([Exit], [1.0])\n",
    "        }\n",
    "    \n",
    "    def actions(self, state) :\n",
    "        \"\"\"returns all valid actions from the current state\"\"\"\n",
    "        if state in self.terminals :\n",
    "            return [Exit]\n",
    "        if state == self.end_state :\n",
    "            return [] #No action available.\n",
    "        return [ Up, Down, Right, Left ]\n",
    "    \n",
    "    def reward(self, state, action, next_state=None) :\n",
    "        \"\"\"reward is the instantaneous reward. It is usually R(s,a,s')\"\"\"\n",
    "        #In grid world the reward depends only on state.\n",
    "        if state in self.terminals :\n",
    "            return self.terminals[state] #dict has the terminal values +1 or -1\n",
    "        if state == self.end_state :\n",
    "            return 0.0\n",
    "        return self.living_reward        #usually a small -ve value\n",
    "    \n",
    "    def transitions(self, state, action) :\n",
    "        \"\"\"returna list of tuple(nextstate, action, probability)\"\"\"\n",
    "        actual_actions, probs = self.action_transitions[action]\n",
    "        return [ self._next_cell(state, a) for a in actual_actions ], actual_actions, probs\n",
    "    \n",
    "    def move(self, state, action) :\n",
    "        \"\"\"Take the action and return the tuple(new_state, reward, is_terminal)\"\"\"                          \n",
    "        assert action in self.actions(state) #just a check if this is a valid action at this time or not\n",
    "        \n",
    "        cells, actions, p = self.transitions(state, action)\n",
    "        \n",
    "        #we choose one cell acccording to probabilities\n",
    "        new_state   = random.choices(cells, weights=p)[0] #only one; we take index 0                \n",
    "        reward      = self.reward(state, action) #\n",
    "        \n",
    "        is_terminal = False\n",
    "        if new_state == self.end_state :\n",
    "            is_terminal = True\n",
    "            \n",
    "        return new_state, reward, is_terminal #keep the same for mat as OpenAI gym.\n",
    "    \n",
    "    def _next_cell(self, state, action) : \n",
    "        \"\"\"Blindly takes the action without checking anything and returns the position\"\"\"\n",
    "        r,c = state #row & column\n",
    "        if action == Exit :\n",
    "            return self.end_state\n",
    "        if action == Up :\n",
    "            target = r-1, c  \n",
    "        if action == Down :\n",
    "            target = r+1, c\n",
    "        if action == Right :\n",
    "            target = r, c+1  \n",
    "        if action == Left :\n",
    "            target = r, c-1 \n",
    "        \n",
    "        if self._valid_cell(target) :\n",
    "            return target\n",
    "        return state #stay put the target is invalid.\n",
    "    \n",
    "    def _valid_cell(self, cell) :\n",
    "        \"\"\"Returns true if the cell is a valid cell\"\"\"\n",
    "        r, c = cell #this may be an illegal node; we need to check\n",
    "        \n",
    "        #is it any of the walls?\n",
    "        if (r,c) in self.walls :\n",
    "            return False\n",
    "        \n",
    "        #is it outside the grid?\n",
    "        if r < 0 or r >= self.rows or c < 0 or c >= self.columns :\n",
    "            return False\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    #pretty print the grid and agent if given.\n",
    "    def print(self, agent_state=None) :\n",
    "        for r in range(self.rows) :\n",
    "            for c in range(self.columns) :\n",
    "                cell = (r,c)\n",
    "                if cell in self.walls :\n",
    "                    print('# ', end='')\n",
    "                elif cell in self.terminals :\n",
    "                    if self.terminals[cell] > 0 :\n",
    "                        print('+', end=' ')\n",
    "                    else :\n",
    "                        print('-', end=' ')\n",
    "                elif cell == agent_state :\n",
    "                    print('@ ', end='')\n",
    "                else :\n",
    "                    print('. ', end='')\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_world=GridWorld(gamma=1.0, living_reward=-0.04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "v={s:0 for s in grid_world.all_states}\n",
    "v.update({(0,3):1})\n",
    "v.update({(1,3):-1})\n",
    "#v.update({(0,2):0.76})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 0): 0,\n",
       " (0, 1): 0,\n",
       " (0, 2): 0,\n",
       " (0, 3): 1,\n",
       " (1, 0): 0,\n",
       " (1, 2): 0,\n",
       " (1, 3): -1,\n",
       " (2, 0): 0,\n",
       " (2, 1): 0,\n",
       " (2, 2): 0,\n",
       " (2, 3): 0,\n",
       " (-1, -1): 0}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    for s in grid_world.all_states:   \n",
    "        result=[]\n",
    "        for ac in grid_world.actions(s):\n",
    "            sd,noneed,p=grid_world.transitions(s,ac)\n",
    "            yy=0\n",
    "            for i in range(len(sd)):\n",
    "                #r=grid_world.reward(s,ac,sd[i])\n",
    "                yy=yy+(p[i]*((grid_world.reward(s,ac,sd[i]))+v[sd[i]]))\n",
    "            result.append(yy)\n",
    "            v.update({s:max(result)})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 0): 0.7927010181242994,\n",
       " (0, 1): 0.8531948452847933,\n",
       " (0, 2): 0.9132068898496833,\n",
       " (0, 3): 1.0,\n",
       " (1, 0): 0.7427010181242992,\n",
       " (1, 2): 0.6561839020886074,\n",
       " (1, 3): -1.0,\n",
       " (2, 0): 0.6852554037060499,\n",
       " (2, 1): 0.6256904883600551,\n",
       " (2, 2): 0.5835289591742714,\n",
       " (2, 3): 0.26065612266773786,\n",
       " (-1, -1): 0}"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Tkinter'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-134-6296fc6d9830>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mTkinter\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEntry\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmainloop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mStringVar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mheight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'Tkinter'"
     ]
    }
   ],
   "source": [
    "from Tkinter import Tk, Entry, mainloop, StringVar\n",
    "\n",
    "root = Tk()\n",
    "\n",
    "height = 5\n",
    "width = 5\n",
    "for i in range(height):  # Rows\n",
    "    for j in range(width):  # Columns\n",
    "        text_var = StringVar()\n",
    "        # here we are setting cell text value\n",
    "        text_var.set('%s%s' % (i, j)) \n",
    "        b = Entry(root, textvariable=text_var)\n",
    "        b.grid(row=i, column=j)\n",
    "mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v={}\n",
    "for i in grid_world.all_states:\n",
    "    print(i)\n",
    "    key=i\n",
    "    v.update({key:0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=2\n",
    "b=4\n",
    "c=5\n",
    "max([a,b,c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q=grid_world.transitions((0,3),2)\n",
    "q[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expected_value(sd,a):\n",
    "    aa=grid_world.transitions(sd,a)\n",
    "    nxt=aa[0][0]\n",
    "    while True:    \n",
    "        if nxt == (-1,-1):\n",
    "            print(\"reached_terminal\")\n",
    "            break\n",
    "        sd1=aa[0][0]\n",
    "        p1=aa[2][0]\n",
    "        r1=grid_world.reward(sd,a,sd1)\n",
    "        sd2=aa[0][1]\n",
    "        p2=aa[2][1]\n",
    "        r2=grid_world.reward(sd,a,sd2)\n",
    "        sd3=aa[0][2]\n",
    "        p3=aa[2][2]\n",
    "        r3=grid_world.reward(sd,a,sd3)\n",
    "        p=p1*r1+p2*r2+p3*r3\n",
    "        vd1=p(r1+v[sd1])#messed up\n",
    "        \n",
    "        return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state (0, 0)\n",
      "state (0, 1)\n",
      "state (0, 2)\n",
      "state (0, 3)\n",
      "state (1, 0)\n",
      "state (1, 2)\n",
      "state (1, 3)\n",
      "state (2, 0)\n",
      "state (2, 1)\n",
      "state (2, 2)\n",
      "state (2, 3)\n",
      "state (-1, -1)\n"
     ]
    }
   ],
   "source": [
    "s=(0,0)\n",
    "for s in grid_world.all_states:\n",
    "    print(\"state\",s)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vds=prob[reward+v[s]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy={(0,0):Right,(0,1):Right,(0,2):Right,(0,3):Exit,(1,0):Up,(1,2):Up,(1,3):Exit,\n",
    "        (1,4):Exit,(2,0):Up,(2,1):Right,(2,2):Up,(2,3):Left}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy={}\n",
    "for s in grid_world.all_states:\n",
    "    if s== (-1,-1):\n",
    "        break\n",
    "    policy.update({s:Up})  \n",
    "    #dicti.update({key:temp})\n",
    "    print(policy)\n",
    "policy.update({(0,3):Exit}) \n",
    "print(\"policy=\",policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nxt=(2,0)\n",
    "reward=0\n",
    "iter=0\n",
    "while True:    \n",
    "    if nxt == (-1,-1):\n",
    "        break\n",
    "    action=policy[nxt]\n",
    "    a=grid_world.move(nxt,action)\n",
    "    nxt=a[0]\n",
    "    reward+=a[1]\n",
    "    iter+=1\n",
    "    print(\"iteration=\",iter,\"action=\",action,\"next=\",nxt,\"reward=\",reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ARM2HAQElCM-"
   },
   "outputs": [],
   "source": [
    "############# I might change the API later ##########\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UiIB6IdtlHJj"
   },
   "outputs": [],
   "source": [
    "class Policy :\n",
    "    def __init__(self, grid_world=None) :\n",
    "        \"\"\"Holds one policy and returns actions according to it\"\"\"\n",
    "        self.grid_world = grid_world\n",
    "        self.policy     = { } #{ state: policy_action}\n",
    "        \n",
    "    def __getitem__(self, state) :\n",
    "        return self.policy[state]\n",
    "    \n",
    "    def __setitem__(self, state, action) :\n",
    "        self.policy[state] = action\n",
    "        \n",
    "    def print(self) :\n",
    "        print_chars = {Up:'^', Down:'v', Right:'>', Left:'<', Exit:'+'}\n",
    "        for state in [(r,c) for r in range(grid_world.rows) for c in range(grid_world.columns)]:\n",
    "            if state not in self.policy :\n",
    "                print('#', end=' ')\n",
    "            else : \n",
    "                print(print_chars[self.policy[state]], end=' ')\n",
    "            if (state[1]+1) % grid_world.columns == 0 :\n",
    "                print(\"\") #just a newline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o8uac7g9lb46"
   },
   "outputs": [],
   "source": [
    "###### Some test code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fh2ZfGg2logH"
   },
   "outputs": [],
   "source": [
    "def random_policy(grid_world) :\n",
    "    \"\"\"returns a random action function\"\"\"\n",
    "    def f(state) :\n",
    "        return random.choice(grid_world.actions(state))\n",
    "    return f\n",
    "\n",
    "def fixed_policy(grid_world) :\n",
    "    p = Policy(grid_world)\n",
    "    p.policy = {state: Up   for state in grid_world.all_states }\n",
    "    p.policy.update({state:Exit for state in grid_world.terminals})\n",
    "    #print(p.policy)\n",
    "    def f(state) :\n",
    "        return p[state]\n",
    "    return f\n",
    "\n",
    "def good_policy(grid_world) :\n",
    "    p = Policy(grid_world)\n",
    "    p.policy = {\n",
    "        (-1, -1) : Exit, #just to avoid some extra checking code\n",
    "        (0,0):Right, (0,1): Right, (0,2): Right, (0,3) : Exit,\n",
    "        (1,0):Up,    (1,1): Right, (1,2): Up,    (1,3) : Exit,\n",
    "        (2,0):Up,    (2,1): Left,  (2,2): Up,    (2,3) : Left,\n",
    "               }\n",
    "    p.policy.update({state:Exit for state in grid_world.terminals})\n",
    "    #print(p.policy)\n",
    "    def f(state) :\n",
    "        return p[state]\n",
    "    return f\n",
    "def my_policy(grid_world) :\n",
    "    p = Policy(grid_world)\n",
    "    p.policy = {\n",
    "        (-1, -1) : Exit, #just to avoid some extra checking code\n",
    "        (0,0):Up, (0,1): Up, (0,2): Up, (0,3) : Exit,\n",
    "        (1,0):Up,    (1,1): Up, (1,2): Up,    (1,3) : Exit,\n",
    "        (2,0):Up,    (2,1): Up,  (2,2): Up,    (2,3) : Up,\n",
    "               }\n",
    "    p.policy.update({state:Exit for state in grid_world.terminals})\n",
    "    #print(p.policy)\n",
    "    def f(state) :\n",
    "        return p[state]\n",
    "    return f\n",
    "    \n",
    "def run(grid_world, state, policy=None) :\n",
    "    \"\"\"runs a full episode and return the total reward\"\"\"\n",
    "    rewards = []\n",
    "    gamma = grid_world.gamma\n",
    "    \n",
    "    time_step = 0\n",
    "    while True :\n",
    "        action = policy(state)\n",
    "        #a.print()\n",
    "        #print(action)\n",
    "        state, r, exited = grid_world.move(state, action)\n",
    "        rewards.append(r * (gamma**time_step) ) #the further we go down, the less we value the reward\n",
    "        if exited :\n",
    "            break    \n",
    "        time_step += 1\n",
    "    return rewards\n",
    "\n",
    "\n",
    "def expected_utility(grid_world, state, policy, N=100) :\n",
    "    \"\"\"run the policy till completion several times and return the expected utility\"\"\"\n",
    "    s = 0.0\n",
    "    for _ in range(N) :\n",
    "        #from the same start state we run till completion, N times\n",
    "        s += sum( run(grid_world, state, policy) )\n",
    "    return s/N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "id": "Te1GnYPLlpNz",
    "outputId": "6375c1e5-a658-4866-bbdf-00bc657e4b98"
   },
   "outputs": [],
   "source": [
    "#page  651; AIMA Book\n",
    "#The utilities of the states in the 4 × 3 world, calculated with γ = 1 and\n",
    "#R(s) = − 0.04 for nonterminal states\n",
    "\n",
    "grid_world = GridWorld(gamma=1.0, living_reward=-0.04)\n",
    "\n",
    "for cell in grid_world.all_states :\n",
    "    print (expected_utility(grid_world, cell, good_policy(grid_world), 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uKEfEoBcltXL"
   },
   "outputs": [],
   "source": [
    "def qvalue(grid_world, state, action, V) :\n",
    "    \"\"\"returns the Q value of the state action pair\"\"\"\n",
    "    #  SUM [  P(s' | s, a) * V(s2) ] of all s' from (s,a)\n",
    "    next_states, actions, p = grid_world.transitions(state, action)\n",
    "    \n",
    "    values = [ p[i] * V[s] for i,s in enumerate(next_states) ]\n",
    "    #print(values)\n",
    "    #print(sum(values))\n",
    "    return sum( values )\n",
    "\n",
    "def max_qvalue(grid_world, state, V) :\n",
    "    \"\"\"returns the maximum of q values and its action\"\"\"\n",
    "    q = [ (qvalue(grid_world, state, action, V), action) for action in grid_world.actions(state) ]\n",
    "    #print(q)\n",
    "    return max(q)\n",
    "\n",
    "def value_iteration(grid_world) :\n",
    "    states = grid_world.all_states\n",
    "    gamma  = grid_world.gamma\n",
    "    #epsilon = 0.0001 * (1-gamma)/gamma\n",
    "    epsilon = 1e-7\n",
    "    \n",
    "    #initialize to 0\n",
    "    U = { s: 0 for s in states }\n",
    "    V = { s: 0 for s in states }\n",
    "    \n",
    "    #difference between U and V. if it is less than epsilon, we are good enough\n",
    "    def diff(U,V) :\n",
    "        return sum([abs(U[s] - V[s]) for s in states])\n",
    "            \n",
    "    for count in range(1000) :\n",
    "        for state in states :\n",
    "            qmax, qaction = max_qvalue(grid_world, state, U)\n",
    "            #print(q)\n",
    "            V[state] = grid_world.reward(state, None) + gamma * qmax\n",
    "            \n",
    "            #print(U)\n",
    "            #print(V)\n",
    "        if diff(U, V) < epsilon : #we are not improving much. Converged?\n",
    "            break\n",
    "                \n",
    "        #print (diff(U, V), epsilon)\n",
    "        U.update(V)\n",
    "    print(count)\n",
    "    return U\n",
    " \n",
    "def policy_from_value(grid_world, V) :\n",
    "    p = Policy(grid_world)\n",
    "    for state in grid_world.all_states :\n",
    "        qmax, qaction = max_qvalue(grid_world, state, V)\n",
    "        p[state] = qaction\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "18mKvMgytNh6"
   },
   "outputs": [],
   "source": [
    "grid_world = GridWorld(gamma=0.9, living_reward=-0.04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "oNafgb8NtR2o",
    "outputId": "a3dd5fe6-8579-4d88-cfdd-2d30e52913c3"
   },
   "outputs": [],
   "source": [
    "V = value_iteration(grid_world)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Li5DOvh4tULe"
   },
   "outputs": [],
   "source": [
    "p = policy_from_value(grid_world, V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "gLWHT7wHuHPk",
    "outputId": "833dff3e-62ff-4426-b9f4-26981b1782fd"
   },
   "outputs": [],
   "source": [
    "p.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PDc3BXIluIUP"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "mdp.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
